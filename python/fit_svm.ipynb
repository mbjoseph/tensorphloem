{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify plant species using SVM with PCA dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Script to read neon plant data and classify plant species using an SVM \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "# read file\n",
    "fileName = \"../derived-data/plants_merged.csv\"\n",
    "df = pd.read_csv(fileName, skiprows = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance retained at 2 dimensions:  0.898208384178\n",
      "Variance retained at 3 dimensions:  0.952364005642\n",
      "Variance retained at 4 dimensions:  0.982838937363\n",
      "Variance retained at 5 dimensions:  0.992810579491\n"
     ]
    }
   ],
   "source": [
    "#Extract taxonid column and assign an integer to each unique species this becomes y vector\n",
    "def getTarget(df):\n",
    "\tspecies = df['taxonid']\n",
    "\tlabels, levels = pd.factorize(species)\n",
    "\ty = labels\n",
    "\treturn y\n",
    "\n",
    "#Extract all columns to be used as features in the svm\n",
    "def getFeatures(df):\n",
    "\tident = 'nm_'\n",
    "\tnames = ['chm_height']\n",
    "\tfor column in df:\n",
    "\t\tif re.match(ident, column):\n",
    "\t\t\tnames.append(column)\n",
    "\tX = df[names]\n",
    "\tX = X.as_matrix()\n",
    "\treturn X\n",
    "\n",
    "y = getTarget(df)\n",
    "X = getFeatures(df)\n",
    "\n",
    "#Normalize features\n",
    "def featureNorm(X):\n",
    "\tX_shape = X.shape\n",
    "\tX_norm = X\n",
    "\tmu = np.mean(X, axis=1)\n",
    "\tsigma = np.std(X, axis = 1)\n",
    "\tfor i in range(X_shape[1]):\n",
    "\t\tX_norm[:,i] = (X[:,i] - mu[i])/sigma[i]\n",
    "\treturn X_norm\n",
    "\n",
    "def reduceDims(X):\n",
    "\tvariance = 0\n",
    "\tn_components = 2\n",
    "\twhile(variance <= .99):\n",
    "\t\tpca = decomposition.PCA(n_components=n_components)\n",
    "\t\tpca.fit(X)\n",
    "\t\tvariance = pca.explained_variance_ratio_.cumsum()[-1]\n",
    "\t\tprint('Variance retained at', n_components, 'dimensions: ', variance)\n",
    "\t\tn_components = n_components + 1\n",
    "\tX = pca.transform(X)\n",
    "\treturn X\n",
    "\n",
    "#Randomize row order\n",
    "def randomizeVals(X, y):\n",
    "\tX_shape = X.shape\n",
    "\tarr = np.column_stack((X, y))\n",
    "\tnp.random.shuffle(arr)\n",
    "\tX = arr[:,0:X_shape[1]]\n",
    "\ty = arr[:,-1]\n",
    "\treturn(X, y)\n",
    "\n",
    "#Seperate data into a training set, cross validation set and test set\n",
    "def getSets(X, y):\n",
    "\ttrain_stop = round(.6 * y.size)\n",
    "\tcv_stop = y.size - round(.2 * y.size)\n",
    "\tX_train = X[0:train_stop, :]\n",
    "\ty_train = y[0:train_stop]\n",
    "\tX_cv = X[train_stop + 1:cv_stop, :]\n",
    "\ty_cv = y[train_stop + 1:cv_stop]\n",
    "\tX_test = X[cv_stop + 1:-1, :]\n",
    "\ty_test = y[cv_stop + 1:-1]\n",
    "\treturn(X_train, X_test, X_cv, y_train, y_test, y_cv)\n",
    "\n",
    "X = featureNorm(X)\n",
    "X = reduceDims(X)\n",
    "(X, y) = randomizeVals(X, y)\n",
    "(X_train, X_test, X_cv, y_train, y_test, y_cv) = getSets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10.0 gamma: 0.01\n",
      "Test Accuracy: 0.642857142857\n"
     ]
    }
   ],
   "source": [
    "#optemize constant parameters of cost function on the cross validation set\n",
    "def findParams(X_train, y_train, X_cv, y_cv):\n",
    "\taccuracy = 0\n",
    "\tparams = np.array([.01, .03, .1, .3, 1, 3, 10, 30])\n",
    "\tfor i in range(params.size):\n",
    "\t\tfor j in range(params.size):\n",
    "\t\t\tC = params[i]\n",
    "\t\t\tgamma = params[j]\n",
    "\t\t\tclf = SVC(C=C, gamma=gamma, decision_function_shape='ovr')\n",
    "\t\t\tclf.fit(X_train, y_train)\n",
    "\t\t\ttemp_acc = clf.score(X_test, y_test)\n",
    "\t\t\tif temp_acc > accuracy:\n",
    "\t\t\t\tclf_ideal = clf\n",
    "\t\t\t\tC_ideal = C\n",
    "\t\t\t\tgamma_ideal = gamma\n",
    "\t\t\t\taccuracy = temp_acc\n",
    "\tprint(\"C:\", C_ideal, \"gamma:\", gamma_ideal)\n",
    "\treturn clf_ideal\n",
    "\n",
    "#check accuracy\n",
    "clf_ideal = findParams(X_train, y_train, X_cv, y_cv)\n",
    "print(\"Test Accuracy:\", clf_ideal.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
